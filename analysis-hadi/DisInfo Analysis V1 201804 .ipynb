{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DisInfo Project Analysis V1 201804\n",
    "# (based on OpenWPM-scan of Haye list on 201804 & earlier lightbeam-scan by Hossein on 201803)\n",
    "# update 20180524: export as matrix for Amir/Marc analysis and for Elsa/Haye check\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from collections import Counter\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "#DPI = 120  # used for graphs. check at: http://www.infobyip.com/detectmonitordpi.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to remove the http, https and extract domains from site_url\n",
    "\n",
    "from tldextract import extract as tldextract  # pip install tldextract\n",
    "\n",
    "def strip_site(site):\n",
    "    \"\"\"Removes leading http:// or https:// and trailing '/'\"\"\"\n",
    "    if site is None:\n",
    "        return None\n",
    "    site = site.lower().strip()\n",
    "    if site.startswith('http'):\n",
    "        site = site.replace('https://', '').replace('http://', '')\n",
    "    if site.startswith('www.'):\n",
    "        site = site[4:]\n",
    "    if site.endswith('/'):\n",
    "        site = site[:-1]\n",
    "    return site\n",
    "\n",
    "def extract_domain(site):\n",
    "    \"\"\"Returns domain+tld from a full domain\"\"\"\n",
    "    site = strip_site(site)  # just to be sure\n",
    "    ext = tldextract(site)\n",
    "    ret = \".\".join([ss for ss in ext[-2:] if ss])\n",
    "    # In case of gov.ie, or IPs, our 'ret' works better than 'ext.registered_domain'\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bool_success\n",
      "-1      2\n",
      " 0     17\n",
      " 1    148\n",
      "Name: site, dtype: int64\n",
      "check RCOUNT>2: 42    koffiepauze.com\n",
      "Name: site, dtype: object\n",
      "check 400/500 errors: 35    zonnewind.be\n",
      "Name: site, dtype: object\n",
      "\n",
      " FINAL 134\n"
     ]
    }
   ],
   "source": [
    "# Q 1- which sites broken to filter\n",
    "#    all broken, of course (success=0). \n",
    "#    also: the ones that returned 404 / plesk / etc? -- would need check\n",
    "\n",
    "dbcon = sqlite3.connect(\"../out/disinfo.20180417.KEEP/crawl-data.sqlite\")\n",
    "\n",
    "# sqlite reference: https://sqlite.org/lang_corefunc.html\n",
    "sites = pd.read_sql_query(\"\"\"SELECT s.visit_id, \n",
    "                            site_url as site, \n",
    "                            bool_success, \n",
    "                            group_concat(response_status) as response_status, \n",
    "                            group_concat(location) as redirect, \n",
    "                            count(*) as response_count\n",
    "                          FROM site_visits s \n",
    "                          LEFT JOIN CrawlHistory h\n",
    "                               ON s.site_url=h.arguments AND h.command='GET'\n",
    "                          LEFT JOIN http_responses r\n",
    "                               ON s.visit_id=r.visit_id AND LOWER(RTRIM(s.site_url))=RTRIM(r.url, '/')\n",
    "                          GROUP BY s.visit_id\"\"\", \n",
    "                          dbcon)\n",
    "       \n",
    "sites[\"site\"] = sites[\"site\"].apply(strip_site)\n",
    "sites[\"redirect\"] = sites[\"redirect\"].apply(strip_site)\n",
    "sites = sites[sites[\"site\"]!= \"geoip.hidemyass.com\"]  # remove our test/vpn site\n",
    "print(sites.groupby(\"bool_success\").site.count())  \n",
    "# bool-success 17:0=non-existant, rest:ok=1 => 2:-1=crash? (zaplog.nl, nieuws.nl)\n",
    "\n",
    "print(\"check RCOUNT>2:\", sites[sites.response_count>1].site)   # koffiepauze.com -- tagged as non-functional\n",
    "t = sites[(sites.response_count==1)&(sites.bool_success==1)].copy()\n",
    "print(\"check 400/500 errors:\", t[t.response_status.astype(int)>=400].site)  # zonnewinde.be, also non-functional\n",
    "del sites[\"response_count\"]  # not needed anymore\n",
    "\n",
    "# ADD site type\n",
    "st = pd.read_csv(\"../indata/disinfo-tracker-site-list-201804b.csv\")  \n",
    "# 20180524: 'b' added, think tld/rank cols delted, screenshot_check renamed to: site-functional\n",
    "#print(st.columns)\n",
    "st[\"site\"] = st[\"site\"].apply(str.lower).apply(str.strip)\n",
    "del st[\"source\"]\n",
    "\n",
    "# combining some types -- to check all (agh, 4 where wrongly classified by me, fixed)\n",
    "st.loc[st[\"site_type\"]==\"NL-opinion-islamic\", \"site_type\"] = \"NL-opinion\"\n",
    "st.loc[st[\"site_type\"]==\"NL-politics-DH\", \"site_type\"] = \"NL-pparties\"\n",
    "st.loc[st[\"site_type\"]==\"NL-politics\", \"site_type\"] = \"NL-pparties\"\n",
    "st.loc[st[\"site_type\"]==\"NL-valse-nieuws\", \"site_type\"] = \"NL-clickbait\"  \n",
    "\n",
    "sites = sites.set_index(\"site\").join(st.set_index(\"site\"))\n",
    "#print(sites.groupby([\"site_type\", \"bool_success\"]).count())  # note: the unsuccess are NL-parties\n",
    "\n",
    "\n",
    "# for now, manually fixing 'not found'/'redirects'\n",
    "# CHECKED: sites[(sites.screenshot_check==0)&(sites.bool_success==1)] \n",
    "#   -- mostly clickbaits that have been since removed; plus tmgonlinemedia/dds/pvvdenhaag\n",
    "# CHECKED: sites[(sites.screenshot_check==1)&(sites.bool_success!=1)]  == None\n",
    "\n",
    "# thus remove unsuccessful sites\n",
    "sites = sites[(sites.bool_success==1)&(sites[\"site-functional\"]==1)]  \n",
    "print(\"\\n FINAL\", len(sites)) \n",
    "\n",
    "#print(sites.groupby([\"site_type]).count())  # final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rename dagelijksfilmpje.nl => coinbids.io\n",
      "rename hetdelenwaard.nl => hetdelenwaard.net\n",
      "rename joop.nl => joop.bnnvara.nl\n",
      "deleting duplicate vk.nl ( volkskrant.nl )\n",
      "rename fvd.nl => forumvoordemocratie.nl\n",
      "deleting duplicate d66denhaag.nl ( denhaag.d66.nl )\n",
      "132\n"
     ]
    }
   ],
   "source": [
    "# 20180524 REDIRECTs => TODO: ELSA!\n",
    "sites.reset_index(inplace=True)\n",
    "mark_del = set()\n",
    "\n",
    "for i, r in sites.iterrows():\n",
    "    if r.redirect != r.site and r.redirect:        \n",
    "        #print(r.site, \"=>\", r.redirect, \"*\" if r.redirect in sites.index else \"\")\n",
    "        \n",
    "        \n",
    "        if r.redirect in set(sites.site):\n",
    "            # duplicate, we can delete it\n",
    "            print('deleting duplicate', r.site, '(', r.redirect, ')')\n",
    "            mark_del.add(r.site)\n",
    "        else:\n",
    "            # otherwise rename it. this is more accurate. see below stats\n",
    "            sites.loc[sites.site==r.site, 'site'] = r.redirect  \n",
    "            print('rename', r.site, '=>', r.redirect)\n",
    "        \n",
    "\n",
    "sites = sites[~sites.site.isin(mark_del)]\n",
    "print(len(sites))\n",
    "sites.set_index('site', inplace=True)\n",
    "        \n",
    "# nothing super interesting here :)        \n",
    "#         dagelijksfilmpje.nl => coinbids.io\n",
    "#         hetdelenwaard.nl => hetdelenwaard.net\n",
    "#         vk.nl => volkskrant.nl *\n",
    "#         joop.nl => joop.bnnvara.nl\n",
    "#         d66denhaag.nl => denhaag.d66.nl *\n",
    "#         fvd.nl => forumvoordemocratie.nl\n",
    "\n",
    "# UPON FURTHER INVESTIATGION, FOR D66 & VK & FVD & JOOP THE REDIRECTED DOMAINS ARE CORRECTER\n",
    "# (in terms of 3rd parties) -- so let's make that change\n",
    "\n",
    "# for s in ['vk.nl', 'volkskrant.nl', 'd66denhaag.nl', 'denhaag.d66.nl', 'fvd.nl', 'joop.nl']:\n",
    "#     ct = cookies[cookies.site==s]            \n",
    "#     jt = js_calls[js_calls.site==s]    \n",
    "#     print(s, set(ct.chost), set(jt.jhost))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dds.nl\n",
      "trendbuzz.nu\n",
      "viraltube.nl\n",
      "nidarotterdam.nl\n",
      "partijvoordedieren.nl\n",
      "sgp.nl\n",
      "axed.nl\n",
      "viraalvandaag.com\n"
     ]
    }
   ],
   "source": [
    "#overlap with hossein list\n",
    "\n",
    "hossein = pd.read_csv(\"../indata/disinfo ThirdPartySites-Hossein 20180323.csv\") \n",
    "hossein[\"site\"] = hossein[\"site\"].apply(lambda x: x.replace(\"www.\", \"\"))\n",
    "hossein = hossein.filter([\"site\", \"thirdparties\"])\n",
    "\n",
    "for s in hossein[\"site\"]:\n",
    "    if s not in sites.index:\n",
    "        print(s)\n",
    "        \n",
    "# some missing -- to add? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cookies: 5880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to cache TLDs in file /opt/miniconda3/lib/python3.6/site-packages/tldextract/.tld_set: [Errno 13] Permission denied: '/opt/miniconda3/lib/python3.6/site-packages/tldextract/.tld_set'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing 1st-parties: 4987\n",
      "removing duplicates: 2321\n",
      "removing short-lived: 1615\n",
      "{'nieuws.nl', 'hetdelenwaard.nl', 'fvd.nl', 'viraltube.nl', 'geoip.hidemyass.com', 'joop.nl', 'vk.nl', 'zaplog.nl', 'viraltrend.nl', 'd66denhaag.nl', 'koffiepauze.com', 'copernicusmarkpeeters.skynetblogs.be', 'dagelijksfilmpje.nl'}\n",
      "removing unsuccseful: 1338\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "      <th>chost</th>\n",
       "      <th>value</th>\n",
       "      <th>expiry_life</th>\n",
       "      <th>cookie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ahealthyme.nl</td>\n",
       "      <td>doubleclick.net</td>\n",
       "      <td>AHWqTUm7qEUguv-R-wXnwyO4lqOMn1zD-_dMkJxqrVB6mG...</td>\n",
       "      <td>390 days</td>\n",
       "      <td>doubleclick.net~IDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>apost.com</td>\n",
       "      <td>adnxs.com</td>\n",
       "      <td>ChgIldY8EAoYASABKAEw4a7Z1gU4AUABSAEQ4a7Z1gUYAA..</td>\n",
       "      <td>90 days</td>\n",
       "      <td>adnxs.com~icu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>apost.com</td>\n",
       "      <td>onesignal.com</td>\n",
       "      <td>d3b207893efd67bfe1ec1c5f8738c7dc21523996511</td>\n",
       "      <td>365 days</td>\n",
       "      <td>onesignal.com~__cfduid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>apost.com</td>\n",
       "      <td>taboola.com</td>\n",
       "      <td>CwsIIBDlgAoMCwgkEOWACgwLCC0Q5YAKDAsIJxDlgAoMDBMU</td>\n",
       "      <td>365 days</td>\n",
       "      <td>taboola.com~stpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>apost.com</td>\n",
       "      <td>taboola.com</td>\n",
       "      <td>CAETCMquPxABFA</td>\n",
       "      <td>365 days</td>\n",
       "      <td>taboola.com~t_vpub</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             site            chost  \\\n",
       "27  ahealthyme.nl  doubleclick.net   \n",
       "34      apost.com        adnxs.com   \n",
       "36      apost.com    onesignal.com   \n",
       "46      apost.com      taboola.com   \n",
       "48      apost.com      taboola.com   \n",
       "\n",
       "                                                value expiry_life  \\\n",
       "27  AHWqTUm7qEUguv-R-wXnwyO4lqOMn1zD-_dMkJxqrVB6mG...    390 days   \n",
       "34   ChgIldY8EAoYASABKAEw4a7Z1gU4AUABSAEQ4a7Z1gUYAA..     90 days   \n",
       "36        d3b207893efd67bfe1ec1c5f8738c7dc21523996511    365 days   \n",
       "46   CwsIIBDlgAoMCwgkEOWACgwLCC0Q5YAKDAsIJxDlgAoMDBMU    365 days   \n",
       "48                                     CAETCMquPxABFA    365 days   \n",
       "\n",
       "                    cookie  \n",
       "27     doubleclick.net~IDE  \n",
       "34           adnxs.com~icu  \n",
       "36  onesignal.com~__cfduid  \n",
       "46        taboola.com~stpt  \n",
       "48      taboola.com~t_vpub  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cookies = pd.read_sql_query(\"\"\"SELECT site_url as site, host as chost, name, value, \n",
    "                                      is_session, change, expiry, creationTime\n",
    "                            FROM site_visits s \n",
    "                            LEFT JOIN javascript_cookies c \n",
    "                            ON s.visit_id=c.visit_id ORDER BY s.visit_id\"\"\", \n",
    "                            dbcon)\n",
    "\n",
    "print(\"cookies:\", len(cookies))\n",
    "\n",
    "# remove null cookies  (q: what are they?)\n",
    "cookies['site'] = cookies[\"site\"].astype(str).apply(strip_site)\n",
    "cookie_null_sites = set(cookies[cookies[\"chost\"].isnull()].site)\n",
    "cookies['chost'] = cookies[\"chost\"].astype(str).apply(extract_domain)\n",
    "cookies = cookies[(~cookies[\"name\"].isnull())]\n",
    "\n",
    "# compare site-domain and cookie domain;  keep only 3rd party cookies\n",
    "comparison_1pd = cookies[\"chost\"] == cookies[\"site\"].apply(extract_domain)\n",
    "cookies = cookies[~comparison_1pd]\n",
    "print(\"removing 1st-parties:\", len(cookies))\n",
    "\n",
    "# if a cookie is changed, keep only last; if deleted, remove. \n",
    "\n",
    "# cookies_US_unique=pd.DataFrame(data=US.drop_duplicates(subset=['name','site_url'],keep='last'))\n",
    "# cookies_US_unique.head()\n",
    "# cookies_US_unique.shape\n",
    "\n",
    "# creates a combo key with ~ for easier checks (does a sanity check that ~ isn't used first)\n",
    "assert not [ix for ix, c in cookies.iterrows() if \"~\" in c[\"site\"] or \"~\" in c[\"chost\"]]#  or \"~\" in c[\"name\"]]\n",
    "cookies[\"combo\"] = cookies[\"site\"] + \"~\" + cookies[\"chost\"] + \"~\" + cookies[\"name\"]\n",
    "tmp_seen = set()\n",
    "tmp_added = list(cookies[cookies.change=='added']['combo'])  \n",
    "for ix in reversed(cookies.index):\n",
    "    sc = cookies.loc[ix, \"combo\"]\n",
    "    if sc not in tmp_seen:\n",
    "        tmp_seen.add(sc)\n",
    "        assert sc in tmp_added  # sanity: make sure any changed/deleted/added cookie was added first\n",
    "    else:\n",
    "        cookies.loc[ix, \"combo\"] = None  # cookie later seen, mark earlier for deletion\n",
    "cookies = cookies[~cookies[\"combo\"].isnull()]\n",
    "del cookies[\"combo\"]\n",
    "print(\"removing duplicates:\", len(cookies))\n",
    "\n",
    "# convert dates and get only cookies that expire in more than 30 days.\n",
    "# (this also takes out the 340 is_session==1)\n",
    "cookies.loc[:,\"expiry\"] = cookies[\"expiry\"].astype('datetime64[ns]') \n",
    "cookies.loc[:,\"creationTime\"] = cookies[\"creationTime\"].astype('datetime64[ns]')\n",
    "cookies[\"expiry_life\"] = cookies.loc[:,\"expiry\"] - cookies.loc[:,\"creationTime\"] \n",
    "cookies = cookies[cookies[\"expiry_life\"] > pd.Timedelta(30,unit='d')]\n",
    "print(\"removing short-lived:\", len(cookies))\n",
    "\n",
    "# remove unsuccessful visits -- not possibly not all where unsuccseful; anyway click-bait group, don't care\n",
    "print(set(cookies[~cookies[\"site\"].isin(sites.index)][\"site\"]))\n",
    "    # removing: {'geoip.hidemyass.com', 'nieuws.nl', 'zaplog.nl'}\n",
    "cookies = cookies[cookies[\"site\"].isin(sites.index)]\n",
    "print(\"removing unsuccseful:\", len(cookies))\n",
    "\n",
    "# simplify dataframe\n",
    "cookies[\"cookie\"] = cookies[\"chost\"] + \"~\" + cookies[\"name\"]\n",
    "del cookies[\"is_session\"], cookies[\"change\"], cookies[\"expiry\"], cookies[\"creationTime\"], cookies[\"name\"]\n",
    "cookies.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get http requests (includes iframes, static resources, js-calls) \n",
    "# => instead I use the JS-calls group (below). that's a bit more conservative. and need to check if it contains FB\n",
    "\n",
    "# http_reqs = pd.read_sql_query(\"\"\"SELECT site_url as site, url as req_url, url as rhost\n",
    "#                                 FROM site_visits s LEFT JOIN http_requests r\n",
    "#                                 ON s.visit_id=r.visit_id \n",
    "#                                 ORDER BY s.visit_id\"\"\", \n",
    "#                                dbcon)\n",
    "# http_reqs['site'] = http_reqs[\"site\"].astype(str).apply(strip_site)\n",
    "# http_reqs['rhost'] = http_reqs[\"rhost\"].astype(str).apply(extract_domain)\n",
    "\n",
    "# # Q: filter at least same domain\n",
    "# comparison_1pd = http_reqs[\"rhost\"] == http_reqs[\"site\"].apply(extract_domain)\n",
    "# http_reqs = http_reqs[~comparison_1pd]\n",
    "# print(len(http_reqs))  \n",
    "\n",
    "# # also filter most basic static resources \n",
    "# # note, images (.png, .jpg, .jpeg, .svg), as well as .js/.html/.... can be/call trackers\n",
    "# comparison_static = http_reqs.req_url.apply(lambda x: x.endswith('.css') or x.endswith('.ttf'))\n",
    "# http_reqs = http_reqs[~comparison_static]\n",
    "# print('removing static', len(http_reqs))  \n",
    "\n",
    "# http_reqs['rcompany'] = http_reqs['rhost']\n",
    "# for h, c in map_domain_company.items():\n",
    "#     http_reqs.loc[http_reqs.rhost==h, 'rcompany'] = c\n",
    "\n",
    "# http_reqs.groupby('rcompany').site.nunique().sort_values(ascending=False)[:15]  # has g-analytics, etc  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_domain_company = {\"google-analytics.com\": \"GOOGLE\",  \n",
    "                     # Q: perhaps separate google-static & not? (check STEVE's paper)\n",
    "                    \"googleapis.com\": \"GOOGLE\",        \n",
    "                    \"gstatic.com\": \"GOOGLE\",\n",
    "                    \"doubleclick.net\": \"GOOGLE\",\n",
    "                    \"google.com\": \"GOOGLE\",\n",
    "                    \"google.nl\": \"GOOGLE\",\n",
    "                    \"googlesyndication.com\": \"GOOGLE\",\n",
    "                    \"googletagmanager.com\": \"GOOGLE\",\n",
    "                    \"googleadservices.com\": \"GOOGLE\",  # Q: why so many google domains??\n",
    "                    \"youtube.com\": \"GOOGLE\",\n",
    "                    \"ytimg.com\": \"GOOGLE\",  # (i could script WHOIS on all of these :)\n",
    "                    \"googletagservices.com\": \"GOOGLE\",\n",
    "                     \"facebook.com\": \"FACEBOOK\",\n",
    "                    \"facebook.net\": \"FACEBOOK\",\n",
    "                    \"fbcdn.net\": \"FACEBOOK\",                    \n",
    "                    \"instagram.com\": \"FACEBOOK\",\n",
    "                    \"twimg.com\": \"twitter.com\",\n",
    "                    \"dummy file\": None,  # for js-urls                    \n",
    "                    # cloudflare.com, scorecardresearch.com, bidswitch.net...\n",
    "                    # cloudfront.net=amazon?\n",
    "                    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jcompany\n",
       "GOOGLE                   118\n",
       "FACEBOOK                  47\n",
       "cloudflare.com            19\n",
       "scorecardresearch.com     18\n",
       "wp.com                    17\n",
       "twitter.com               17\n",
       "gravatar.com              13\n",
       "taboola.com               12\n",
       "cloudfront.net            11\n",
       "rootads.nl                10\n",
       "adnxs.com                  7\n",
       "statcounter.com            7\n",
       "chartbeat.com              6\n",
       "sharethis.com              5\n",
       "sprinklecontent.com        5\n",
       "Name: site, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jhost NOT needed, all of these appear in the rhost. \n",
    "# BUT maybe a btit more conservative re js vs static elements (e.g. css)\n",
    "js_calls = pd.read_sql_query(\"\"\"SELECT site_url as site, script_url as js_url, script_url as jhost\n",
    "                                FROM site_visits s LEFT JOIN javascript j\n",
    "                                ON s.visit_id=j.visit_id \n",
    "                                WHERE script_url is not null\n",
    "                                ORDER BY s.visit_id\"\"\", dbcon)\n",
    "js_calls['site'] = js_calls[\"site\"].astype(str).apply(strip_site)\n",
    "js_calls['jhost'] = js_calls[\"jhost\"].astype(str).apply(extract_domain)\n",
    "js_calls.groupby('jhost').site.nunique().sort_values(ascending=False)[:10]  \n",
    "\n",
    "# Q: filter same domain\n",
    "comparison_1pd = js_calls[\"jhost\"] == js_calls[\"site\"].apply(extract_domain)\n",
    "js_calls = js_calls[~comparison_1pd]\n",
    "\n",
    "# remove 'dummy file' -- not sure what it is\n",
    "js_calls = js_calls[js_calls.js_url!='dummy file']  # approx 400 call (1.5%)\n",
    "\n",
    "# STRIP QUERY from js\n",
    "js_calls.js_url = js_calls.js_url.apply(lambda x: urlparse(x).netloc + urlparse(x).path)  \n",
    "\n",
    "# # map to company when known\n",
    "js_calls['jcompany'] = js_calls['jhost']\n",
    "for h, c in map_domain_company.items():\n",
    "    js_calls.loc[js_calls.jhost==h, 'jcompany'] = c\n",
    "\n",
    "js_calls.groupby('jcompany').site.nunique().sort_values(ascending=False)[:15]  # has g-analytics, etc  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccompany\n",
      "GOOGLE                   57\n",
      "scorecardresearch.com    23\n",
      "bidswitch.net            18\n",
      "adnxs.com                18\n",
      "adsrvr.org               18\n",
      "FACEBOOK                 12\n",
      "mathtag.com              11\n",
      "taboola.com              11\n",
      "rubiconproject.com       10\n",
      "everesttech.net           9\n",
      "Name: site, dtype: int64\n",
      "ccompany\n",
      "GOOGLE                   88\n",
      "bidswitch.net            54\n",
      "scorecardresearch.com    46\n",
      "taboola.com              43\n",
      "adnxs.com                39\n",
      "Name: site, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# NOW: top 3rd parties overall (domain)\n",
    "\n",
    "# trackers = cookies.groupby('chost').site.count()  # .count() = TOTAL cookies \n",
    "# print(trackers.sort_values(ascending=False)[:5])  # \n",
    "\n",
    "cookies['ccompany'] = cookies['chost']\n",
    "# map_chost_company = {\n",
    "#     \"doubleclick.net\": \"GOOGLE\",\n",
    "#     \"youtube.com\": \"GOOGLE\",\n",
    "# }\n",
    "for h, c in map_domain_company.items():\n",
    "    cookies.loc[cookies.chost==h, 'ccompany'] = c\n",
    "    \n",
    "print(cookies.groupby('ccompany').site.nunique().sort_values(ascending=False)[:10]) # .nunique = one per domain\n",
    "print(cookies.groupby('ccompany').site.count().sort_values(ascending=False)[:5])\n",
    "\n",
    "# cookies[cookies.chost==\"360yield.com\"].groupby('chost').site.count()  # total cookies of this type\n",
    "# cookies[cookies.chost==\"360yield.com\"].groupby('chost').site.nunique()  # on how many sites\n",
    "\n",
    "# (combine groups, e.g. youtube + doubleclick same, manually => reduce overlap to calculate percentages )\n",
    "# (could give output as pie-chart too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_ = cookies.filter([\"site\", \"ccompany\"])\n",
    "ct_.columns = [\"site\", \"tracker\"]\n",
    "jt_ = js_calls.filter([\"site\", \"jcompany\"])\n",
    "jt_.columns = [\"site\", \"tracker\"]\n",
    "combo = ct_.append(jt_)\n",
    "\n",
    "sum(combo.groupby('tracker').site.nunique() >= 15)\n",
    "#, len(set(cookies.ccompany))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sites[sites.site_type.isnull()]\n",
    "#sum(cookies.is_session==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NL-nieuws 14 / 18 of 21 => 14 2 3.0\n",
      "NL-opinion 18 / 22 of 25 => 20 10 3.5\n",
      "NL-clickbait 53 / 56 of 61 => 55 32 5.5\n",
      "NL-pparties 7 / 18 of 25 => 15 6 2.0\n"
     ]
    }
   ],
   "source": [
    "# trackers per (site) category\n",
    "mm = set()\n",
    "\n",
    "for t in [\"nieuws\", \"opinion\", \"clickbait\", \"pparties\"]:\n",
    "    t = \"NL-\" + t\n",
    "    ct = cookies.join(sites, on=\"site\")\n",
    "    ct = ct[ct[\"site_type\"]==t]\n",
    "        \n",
    "    jt = js_calls.join(sites, on=\"site\")\n",
    "    jt = jt[jt[\"site_type\"]==t]\n",
    "    \n",
    "    #rt = http_reqs.join(sites, on=\"site\")\n",
    "    #rt = rt[rt[\"site_type\"]==t]    \n",
    "    # assert len(set(rt.site)) - len(set(jt.site)) <= 3  # we are using the more conservative JT \n",
    "        \n",
    "    ct_ = ct.filter([\"site\", \"ccompany\"])\n",
    "    ct_.columns = [\"site\", \"tracker\"]\n",
    "    jt_ = jt.filter([\"site\", \"jcompany\"])\n",
    "    jt_.columns = [\"site\", \"tracker\"]\n",
    "    combo = ct_.append(jt_)\n",
    "    have_g = set(combo[combo[\"tracker\"]==\"GOOGLE\"].site)\n",
    "    have_fb = set(combo[combo[\"tracker\"]==\"FACEBOOK\"].site)\n",
    "    med_t = combo.groupby(\"site\").tracker.nunique().median()\n",
    "    \n",
    "    \n",
    "    print(t, len(set(ct.site)), \"/\", len(set(jt.site)),\n",
    "          \"of\", len(sites[sites[\"site_type\"]==t]),\n",
    "          \"=>\", len(have_g), len(have_fb), med_t)\n",
    "    \n",
    "    m = set(st.index) - set(ct.site)\n",
    "    #print(m, m & cookie_null_sites)\n",
    "    mm |= m\n",
    "        \n",
    "# MADE A NICE TABLE BASED ON THIS FOR REPORT\n",
    "\n",
    "# NOTE 20180524\n",
    "# removing the 'dummy file' group we get 1-less js for news & pparty\n",
    "\n",
    "# with rename/removal of 2, we have:\n",
    "# 14+1/18+2 from 21+2\n",
    "# 18+1/22+1 from 25+0\n",
    "# 53+2/56+2 from 61+0\n",
    "# 7+2/18+3 from 25+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:    \n",
    "# - CHECKED ALL 36, ALL CRAWLED SUCCESSFULY. (i.e. this is different from 18 that didn't load)\n",
    "#    A BUNCH HAVE COOKIEWALLS, others unclear \n",
    "#    what disntiguishes the 'nullgroup' list? -- I cannot tell any difference\n",
    "#    could it be a bug?    \n",
    "# print(m, m & cookie_null_sites)\n",
    "# mm = [(sites.loc[s, \"visit_id\"], s) for s in mm]  \n",
    "# sorted(mm, key=lambda x:x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ahealthyme.nl => 1 13\n",
      "apost.com => 135 25\n",
      "belfort-group.eu => 0 0\n",
      "bestgezond.nl => 6 9\n",
      "bewustnieuws.nl => 0 0\n",
      "blikopnosjournaal.blogspot.nl => 4 23\n",
      "boinnk.nl => 6 7\n",
      "brekendnieuws.nl => 14 17\n",
      "coinbids.io => 0 0\n",
      "dagelijks.nu => 2 14\n",
      "delangemars.nl => 3 16\n",
      "destillewaarheid.nl => 1 7\n",
      "earth-matters.nl => 1 10\n",
      "echtekrant.be => 3 2\n",
      "ellaster.nl => 0 4\n",
      "gewoon-nieuws.nl => 9 20\n",
      "healthbytes.me => 6 23\n",
      "healthunity.pw => 11 17\n",
      "healthwatch.nu => 21 33\n",
      "hetdelenwaard.net => 0 0\n",
      "hln.be => 49 21\n",
      "jdreport.com => 6 28\n",
      "journaalflash.wordpress.com => 65 13\n",
      "klokkenluideronline.is => 6 14\n",
      "langleveeuropa.nl => 0 0\n",
      "leeftips.nl => 157 21\n",
      "leeshetnu.nl => 2 6\n",
      "lekkerwonen.org => 14 25\n",
      "lijstverse.nl => 4 15\n",
      "likemag.com => 1 8\n",
      "livekijken.nl => 2 4\n",
      "martinvrijland.nl => 3 20\n",
      "niburu.co => 1 1\n",
      "niet100.tv => 1 6\n",
      "nieuwetijdskind.com => 2 16\n",
      "nieuws-dump.nl => 20 17\n",
      "nieuwsblad.be => 12 40\n",
      "nieuwsprimeur.wordpress.com => 10 8\n",
      "nieuwstrend.nu => 1 11\n",
      "not100.nl => 2 9\n",
      "ongelooflijk.nu => 24 21\n",
      "pauwnieuws.nl => 4 10\n",
      "prankster.nl => 4 6\n",
      "revolutionaironline.com => 7 12\n",
      "smakelijk.co => 21 19\n",
      "smullen-maar.nl => 20 18\n",
      "snuggerd.nl => 1 1\n",
      "tis-wat.nl => 18 19\n",
      "trendbuzz.nl => 129 13\n",
      "trendnieuws.nl => 15 25\n",
      "trendnova.nl => 1 5\n",
      "uitgelicht.nu => 19 10\n",
      "united-lightworkers.be => 0 2\n",
      "vaccinatieraad.nl => 2 17\n",
      "viraal.nu => 0 8\n",
      "viraalpunt.nl => 1 7\n",
      "viralmundo.nl => 3 17\n",
      "viralnext.nl => 2 16\n",
      "vrouwendingen.com => 23 19\n",
      "wanttoknow.be => 4 14\n",
      "xandernieuws.punt.nl => 1 5\n",
      "ad.nl => 1 3\n",
      "bnr.nl => 3 5\n",
      "een.be => 30 18\n",
      "eenvandaag.avrotros.nl => 3 3\n",
      "elsevierweekblad.nl => 0 1\n",
      "fd.nl => 0 6\n",
      "frontpage.fok.nl => 1 0\n",
      "kpnvandaag.nl => 0 2\n",
      "news.google.com => 0 4\n",
      "nos.nl => 3 3\n",
      "npo.nl => 3 3\n",
      "nrc.nl => 2 3\n",
      "nu.nl => 7 17\n",
      "parool.nl => 1 2\n",
      "rd.nl => 2 5\n",
      "rtl.nl => 0 0\n",
      "rtlnieuws.nl => 0 4\n",
      "rtlz.nl => 2 3\n",
      "telegraaf.nl => 2 3\n",
      "trouw.nl => 0 0\n",
      "volkskrant.nl => 1 3\n",
      "bovendien.com => 0 0\n",
      "dagelijksestandaard.nl => 95 21\n",
      "dekanttekening.nl => 4 8\n",
      "demet.nl => 0 5\n",
      "demoslimkrant.nl => 2 8\n",
      "dutchfreepress.nl => 1 2\n",
      "ejbron.wordpress.com => 4 13\n",
      "eunmask.wordpress.com => 12 9\n",
      "fenixx.org => 0 6\n",
      "frontaalnaakt.nl => 3 6\n",
      "geenstijl.nl => 3 2\n",
      "groenemoslims.nl => 0 0\n",
      "jalta.nl => 3 18\n",
      "joop.bnnvara.nl => 0 0\n",
      "joostniemoller.nl => 0 2\n",
      "krapuul.nl => 4 9\n",
      "kudtkoekiewet.nl => 1 1\n",
      "nieuwwij.nl => 2 2\n",
      "ninefornews.nl => 147 42\n",
      "opiniez.com => 57 19\n",
      "republiekallochtonie.nl => 0 1\n",
      "tpo.nl => 34 32\n",
      "turksnieuws.nl => 3 17\n",
      "wijblijvenhier.nl => 1 9\n",
      "worldunity.me => 4 21\n",
      "50pluspartij.nl => 0 1\n",
      "bewegingdenk.nl => 1 8\n",
      "cda.nl => 0 2\n",
      "cdadenhaag.nl => 0 5\n",
      "christenunie.nl => 0 2\n",
      "d66.nl => 0 0\n",
      "denhaag.christenunie.nl => 0 1\n",
      "denhaag.d66.nl => 0 0\n",
      "denhaag.groenlinks.nl => 0 0\n",
      "denhaag.nida.nl => 0 0\n",
      "denhaag.partijvoordedieren.nl => 0 0\n",
      "denhaag.pvda.nl => 1 2\n",
      "denhaag.sp.nl => 0 2\n",
      "forumvoordemocratie.nl => 0 0\n",
      "groenlinks.nl => 0 0\n",
      "haagsestadspartij.nl => 3 9\n",
      "hartvoordenhaag.nl => 1 2\n",
      "islamdemocraten.nl => 4 4\n",
      "partijvandeeenheid.nl => 0 4\n",
      "pvda.nl => 0 3\n",
      "pvdd.nl => 0 1\n",
      "pvv.nl => 3 5\n",
      "sp.nl => 0 1\n",
      "vvd.nl => 0 1\n",
      "vvddenhaag.nl => 4 3\n"
     ]
    }
   ],
   "source": [
    "# 20180524. This is the output I'll craete:\n",
    "\n",
    "# two columns: website, our category. \n",
    "#              (REDIRECTED TO -- remove *, others keep original perhaps?)\n",
    "#        \n",
    "# other columns: trackers-http, trackers-js  -- based on domain.\n",
    "\n",
    "# STILL open (method) QUESTIONS:\n",
    "# - cookiewalls? => the new random clicks will find \n",
    "# - (check list -- are we say remivng third party calls from VK to volkskrant.com? => fixeD)\n",
    "# - (what explains null cookies? cookiewalls? crashes?)\n",
    "# - Q ROB/STEVE/ELSA: also what if cookies have same name/values (long strings) -- on different sites?\n",
    "\n",
    "# additional file saying who tracking domains are  => TO COMPLETE ELSA\n",
    "# - need some taxonomy (category of 3rd parties) to understand who/why they are used \n",
    "#   (e.g. ad business? other tracker? google owned like YT/DC?)\n",
    "# - will be completed by elsa (manually; also info on domains;)\n",
    "# - (this can also be checked agains tghostery list)\n",
    "\n",
    "\n",
    "# IMPORTANT CHECK\n",
    "# - does it include FACEBOOK LIKE BUTTON?? (or sth else)\n",
    "# - why so many GOGOLE domains. in particular: GOOGLE static? => SEE: steve's paper\n",
    "#   - google analytics cookie: ahealthyme.nl~_gid  -- 1st party??? -- how???\n",
    "#     (https://developers.google.com/analytics/devguides/collection/analyticsjs/cookie-usage)\n",
    "#   - doubleclick.net short-lived cookies = ??\n",
    "\n",
    "\n",
    "# SITE LIST/CATEGORY => for Haye: \n",
    "# - manually check/confirm site categories & completeness \n",
    "# - are these missing? a few are at least redirecting, i think. rest perhaps need to be indexed\n",
    "#   joop.bnnvara.nl, forumvoordemocratie.nl, nidarotterdam.nl, partijvoordedieren.nl, sgp.nl, axed.nl, viraalvandaag.com\n",
    "# - also what thomas found\n",
    "\n",
    "\n",
    "all_cts = set()\n",
    "all_jts = set()\n",
    "\n",
    "msites = sites.reset_index().sort_values(by=['site_type', 'site'])\n",
    "msites = msites[~msites.site.isin(['vk.nl', 'd66denhaag.nl'])]  # FIX: we don't want the redirects\n",
    "\n",
    "for i, r in msites.iterrows():   \n",
    "    ct = cookies[cookies.site==r.site]            \n",
    "    jt = js_calls[js_calls.site==r.site]    \n",
    "    all_cts |= set(ct.chost.apply(lambda x: x+'/c'))\n",
    "    all_jts |= set(jt.jhost.apply(lambda x: x+'/j'))    \n",
    "\n",
    "    \n",
    "# 63 in both: len(all_cts & all_jts); 198 cookies 135 javascript\n",
    "#print(len(sites), len(all_ctjt))    \n",
    "mcols = [\"category\"] + sorted(all_cts | all_jts)\n",
    "\n",
    "\n",
    "\n",
    "matrix = pd.DataFrame(columns=mcols, index=msites.site)\n",
    "#print(mcols, matrix.index)\n",
    "\n",
    "for s in matrix.index:\n",
    "    matrix.loc[s,'category'] = sites.loc[s, 'site_type']\n",
    "\n",
    "    \n",
    "for i, r in msites.iterrows():   \n",
    "    print(r.site, end=' => ')\n",
    "    n_c, n_j = 0, 0\n",
    "    \n",
    "    # TODO: this innter loop must have some simpler matrix way in pandas :)\n",
    "    \n",
    "    for c in all_cts:\n",
    "        ct = cookies[(cookies.site==r.site)&(cookies.chost==c[:-2])]\n",
    "        matrix.loc[r.site, c] = len(ct)\n",
    "        n_c += len(ct)\n",
    "        \n",
    "    for j in all_jts:\n",
    "        jt = js_calls[(js_calls.site==r.site)&(js_calls.jhost==j[:-2])]\n",
    "        matrix.loc[r.site, j] = len(set(jt.js_url))\n",
    "        n_j += len(set(jt.js_url))\n",
    "        #for jj in set(jt.js_url):  n_jj += 1 if jj.endswith(\".js\") else 0\n",
    "            \n",
    "    print(n_c, n_j)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matrix.head()  #=> ADD CATEGORY => what's NAN??\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "NL-clickbait    53\n",
      "NL-nieuws       14\n",
      "NL-opinion      18\n",
      "NL-pparties      7\n",
      "Name: tot_c, dtype: int64\n",
      "category\n",
      "NL-clickbait    56\n",
      "NL-nieuws       18\n",
      "NL-opinion      22\n",
      "NL-pparties     18\n",
      "Name: tot_j, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#matrix.to_csv(\"~/disinfo-trackers-matrixout-crawl201804.csv\")\n",
    "\n",
    "# sanity checks\n",
    "matrix2 = matrix.copy()\n",
    "for c in matrix2:\n",
    "    if c == 'category':\n",
    "        continue\n",
    "    matrix2[c] =    matrix2[c].apply(lambda x: 1 if x>0 else 0)\n",
    "    #break\n",
    "\n",
    "matrix2['tot_c'] = 0\n",
    "matrix2['tot_j'] = 0\n",
    "\n",
    "    \n",
    "for c in matrix2:\n",
    "    if c.endswith('/c'):\n",
    "        matrix2['tot_c'] += matrix2[c]\n",
    "    if c.endswith('/j'):\n",
    "        matrix2['tot_j'] += matrix2[c]\n",
    "\n",
    "matrix2['tot_c'] = matrix2['tot_c'].apply(lambda x: 1 if x>0 else 0)\n",
    "matrix2['tot_j'] = matrix2['tot_j'].apply(lambda x: 1 if x>0 else 0)\n",
    "\n",
    "print(matrix2.groupby('category').sum().tot_c)\n",
    "print(matrix2.groupby('category').sum().tot_j)\n",
    "\n",
    "\n",
    "# NL-nieuws 14 / 18 of 21 => 14 2 3.0\n",
    "# NL-opinion 18 / 22 of 25 => 20 10 3.5\n",
    "# NL-clickbait 53 / 56 of 61 => 55 32 5.5\n",
    "# NL-pparties 7 / 18 of 25 => 15 6 2.0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
